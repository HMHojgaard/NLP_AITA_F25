{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af6e2b31",
   "metadata": {},
   "source": [
    "# AITA Moral Judgement - NLP Exam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1e397e",
   "metadata": {},
   "source": [
    "Notebook Structure\n",
    "0) Setup & Reproducibility\n",
    "1) Load and preprocess training data\n",
    "2) Train/validation split\n",
    "3) TF-IDF + Logistic Regression (baseline)\n",
    "4) DistilBERT \n",
    "5) DistilBERT fine-tuning (1 epoch)\n",
    "6) DistilBERT fine-tuning (2 epochs)\n",
    "7) DistilBERT (2 epochs) with class-weighted loss\n",
    "8) External dataset evaluation\n",
    "9) Token-level interpretability (Grad × Input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c1eab",
   "metadata": {},
   "source": [
    "## 0) Setup Chunck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a72ebf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.2.3)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.8-cp310-cp310-macosx_11_0_arm64.whl.metadata (52 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.45.2)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.5.0)\n",
      "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.0.1)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.61.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (10.2.0)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets) (1.15.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Downloading matplotlib-3.10.8-cp310-cp310-macosx_11_0_arm64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "Using cached contourpy-1.3.2-cp310-cp310-macosx_11_0_arm64.whl (253 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.61.1-cp310-cp310-macosx_10_9_universal2.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached kiwisolver-1.4.9-cp310-cp310-macosx_11_0_arm64.whl (65 kB)\n",
      "Downloading pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib, seaborn, evaluate\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 evaluate-0.4.6 fonttools-4.61.1 kiwisolver-1.4.9 matplotlib-3.10.8 pyparsing-3.3.1 seaborn-0.13.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate>=0.26.0) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate>=0.26.0) (24.1)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate>=0.26.0) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate>=0.26.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate>=0.26.0) (2.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate>=0.26.0) (0.26.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate>=0.26.0) (0.4.5)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.2.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate>=0.26.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.8.30)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas matplotlib seaborn scikit-learn transformers torch datasets evaluate \n",
    "\n",
    "%pip install 'accelerate>=0.26.0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4153719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "#Core stuff\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# plit + classical ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#Transformers \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import Dataset\n",
    "import evaluate \n",
    "import accelerate\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertForSequenceClassification,\n",
    "    DataCollatorWithPadding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9b6b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: /Users/hannahmaihojgaard/Documents/GitHub/NLP_AITA_F25\n"
     ]
    }
   ],
   "source": [
    "#Repo root\n",
    "REPO_ROOT = Path.cwd()\n",
    "\n",
    "DATA_DIR = REPO_ROOT / \"data\"   \n",
    "OUT_REPORTS = REPO_ROOT / \"classification_reports\"\n",
    "OUT_PLOTS   = REPO_ROOT / \"plots_results\"\n",
    "OUT_TABLES  = REPO_ROOT / \"tables_results\"\n",
    "OUT_TOKENS  = REPO_ROOT / \"bert_token\"\n",
    "\n",
    "for d in [OUT_REPORTS, OUT_PLOTS, OUT_TABLES, OUT_TOKENS]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Repo root:\", REPO_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3993e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output subfolders\n",
    "OUT_REPORTS_BERT  = OUT_REPORTS / \"bert\"\n",
    "OUT_REPORTS_TFIDF = OUT_REPORTS / \"tfidf\"\n",
    "\n",
    "OUT_PLOTS_BERT  = OUT_PLOTS / \"bert\"\n",
    "OUT_PLOTS_TFIDF = OUT_PLOTS / \"tfidf\"\n",
    "\n",
    "for d in [OUT_REPORTS_BERT, OUT_REPORTS_TFIDF, OUT_PLOTS_BERT, OUT_PLOTS_TFIDF]:\n",
    "    d.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "752ad64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed\n",
    "SEED = 200\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d35ead3",
   "metadata": {},
   "source": [
    "## 1) Load in Data + Preprocessing of the primary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a8a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training/validation dataset\n",
    "path = DATA_DIR / \"data_train_val.csv\"\n",
    "raw_df = pd.read_csv(path)\n",
    "\n",
    "#raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2489531c",
   "metadata": {},
   "source": [
    "## 2) Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ceec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (97628, 9)\n",
      "Columns: ['id', 'timestamp', 'title', 'body', 'edited', 'verdict', 'score', 'num_comments', 'is_asshole']\n"
     ]
    }
   ],
   "source": [
    "#df info\n",
    "print(\"Shape:\", raw_df.shape)\n",
    "print(\"Columns:\", list(raw_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a1842",
   "metadata": {},
   "source": [
    "#### Preprocessing Pipeline \n",
    " 1) Drop empty/NaN body text (moral judgment needs narrative context)\n",
    " 2) Remove is_asshole if present (binary label conflicts with 3-class task)\n",
    " 3) Combine title + body into one text field\n",
    " 4) Map verdict strings to numeric labels: 0=YTA, 1=NTA, 2=ES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79655c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a copy of raw_df\n",
    "df = raw_df.copy()\n",
    "\n",
    "#Drop empty bodies\n",
    "df[\"body\"] = df[\"body\"].fillna(\"\")\n",
    "df = df[df[\"body\"].str.strip().astype(bool)].copy()\n",
    "\n",
    "#Drop binary variable \n",
    "df = df.drop(columns=[\"is_asshole\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e573487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining clean_text function\n",
    "def clean_text(t: str) -> str:\n",
    "    t = str(t)\n",
    "    t = re.sub(r'^\\s*\\[?\\s*aita\\s*\\]?\\s*', '', t, flags=re.IGNORECASE)  # remove \"[AITA]\"\n",
    "    t = re.sub(r\"http\\S+\", \"\", t)                                       # remove URLs\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()                                  # normalize spaces\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d0f684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building text\n",
    "df[\"title\"] = df[\"title\"].fillna(\"\")                                   #Combining title + post\n",
    "df[\"text\"] = (df[\"title\"] + \" \" + df[\"body\"]).apply(clean_text)        #Applying clean_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a722a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map verdict -> labels\n",
    "label_map = {\n",
    "    \"asshole\": 0,           # YTA\n",
    "    \"not the asshole\": 1,   # NTA\n",
    "    \"everyone sucks\": 2     # ES\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3690f576",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"verdict_norm\"] = df[\"verdict\"].astype(str).str.strip().str.lower()\n",
    "df[\"labels\"] = df[\"verdict_norm\"].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1142713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows with verdicts outside YTA/NTA/ES.\n",
      "Final shape: (85539, 2)\n",
      "Label distribution:\n",
      " labels\n",
      "0    20921\n",
      "1    59068\n",
      "2     5550\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I wrote an explanation in TIL and came off as ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Threw my parent's donuts away My parents are d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I told a goth girl she looked like a clown. I ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>: Argument I had with another redditor in r/HIMYM</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Had a disagreement about Les Miserables with a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  I wrote an explanation in TIL and came off as ...       0\n",
       "1  Threw my parent's donuts away My parents are d...       0\n",
       "2  I told a goth girl she looked like a clown. I ...       1\n",
       "3  : Argument I had with another redditor in r/HIMYM       2\n",
       "4  Had a disagreement about Les Miserables with a...       0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check after cleaning\n",
    "before = len(df)\n",
    "df = df[df[\"labels\"].notna()].copy()\n",
    "after = len(df)\n",
    "print(f\"Dropped {before - after} rows with verdicts outside YTA/NTA/ES.\")\n",
    "\n",
    "df[\"labels\"] = df[\"labels\"].astype(int)\n",
    "\n",
    "# Keep only what we need for modeling\n",
    "df = df[[\"text\", \"labels\"]].reset_index(drop=True)\n",
    "\n",
    "print(\"Final shape:\", df.shape)\n",
    "print(\"Label distribution:\\n\", df[\"labels\"].value_counts().sort_index())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7ed160",
   "metadata": {},
   "source": [
    "### 3) Train/Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acacca3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 68431  Val size: 17108\n",
      "\n",
      "Train label distribution:\n",
      " labels\n",
      "1    0.690535\n",
      "0    0.244582\n",
      "2    0.064883\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Val label distribution:\n",
      " labels\n",
      "1    0.690554\n",
      "0    0.244564\n",
      "2    0.064882\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.20,          # 80% train, 20% validation\n",
    "    random_state=SEED,\n",
    "    stratify=df[\"labels\"]    # preserve label distribution\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(train_df), \" Val size:\", len(val_df))\n",
    "print(\"\\nTrain label distribution:\\n\", train_df[\"labels\"].value_counts(normalize=True))\n",
    "print(\"\\nVal label distribution:\\n\", val_df[\"labels\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19caec46",
   "metadata": {},
   "source": [
    "### 4) Baseline TF-IDF + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec817d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions for TF-IDF vectorization, model fitting, and evaluation\n",
    "\n",
    "def vectorize_tfidf(X_train, X_val, max_features=10000):\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        lowercase=True,\n",
    "        max_features=max_features,\n",
    "        ngram_range=(1, 2)\n",
    "    )\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_val_vec = vectorizer.transform(X_val)\n",
    "    return X_train_vec, X_val_vec, vectorizer\n",
    "\n",
    "\n",
    "def clf_fit(X_train_vec, y_train, random_state=42):\n",
    "    clf = LogisticRegression(\n",
    "        random_state=random_state,\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=1000,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def clf_evaluate(clf, X_val_vec, y_val, label_names=(\"YTA\", \"NTA\", \"ES\"),\n",
    "                 save_path=None, title=\"TF-IDF + Logistic Regression\"):\n",
    "    y_pred = clf.predict(X_val_vec)\n",
    "\n",
    "    print(classification_report(y_val, y_pred, target_names=list(label_names)))\n",
    "\n",
    "    cm = confusion_matrix(y_val, y_pred, labels=[0, 1, 2])\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=label_names)\n",
    "    disp.plot(values_format=\"d\")\n",
    "    plt.title(title)\n",
    "\n",
    "    # Save plot (same plot, just saved to the right folder)\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236dc930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run TF-IDF baseline\n",
    "X_train_vec, X_val_vec, tfidf_vectorizer = vectorize_tfidf(train_df[\"text\"], val_df[\"text\"])\n",
    "clf = clf_fit(X_train_vec, train_df[\"labels\"])\n",
    "\n",
    "tfidf_cm_path = OUT_PLOTS_TFIDF / \"TF-IDF+logisticregression_cm.png\"\n",
    "y_pred_baseline = clf_evaluate(\n",
    "    clf,\n",
    "    X_val_vec,\n",
    "    val_df[\"labels\"],\n",
    "    save_path=tfidf_cm_path\n",
    ")\n",
    "\n",
    "#Save classification report\n",
    "tfidf_report = classification_report(\n",
    "    val_df[\"labels\"],\n",
    "    y_pred_baseline,\n",
    "    target_names=[\"YTA\", \"NTA\", \"ES\"],\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_report).transpose()\n",
    "tfidf_df.to_csv(OUT_REPORTS_TFIDF / \"tfidf_classification_report.csv\")\n",
    "\n",
    "#View\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcdffb3",
   "metadata": {},
   "source": [
    "### 5) DistilBERT fine-tuning (1 epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "746a36ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure labels are integers\n",
    "train_df[\"labels\"] = train_df[\"labels\"].astype(int)\n",
    "val_df[\"labels\"]   = val_df[\"labels\"].astype(int)\n",
    "\n",
    "# Convert to Hugging Face Datasets\n",
    "train_hf = Dataset.from_pandas(train_df[[\"text\", \"labels\"]].reset_index(drop=True))\n",
    "val_hf   = Dataset.from_pandas(val_df[[\"text\", \"labels\"]].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ced545e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971f7706c4b74bfa844f48398d175707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6c3d809c8f46f4942b29bf23233579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0628b333c5d04b0391c5528849f3cb9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735a714fa3d048f2bed7461c74672e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load in model and tokenizer\n",
    "model_id = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d845da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization function applied to all texts (truncation enabled for long posts)\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_train = train_hf.map(preprocess_function, batched=True)\n",
    "tokenized_val   = val_hf.map(preprocess_function, batched=True)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "id2label = {0: \"YTA\", 1: \"NTA\", 2: \"ES\"}\n",
    "label2id = {\"YTA\": 0, \"NTA\": 1, \"ES\": 2}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\"f1_macro\": f1_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db3986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining training arguments and trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./training/distilbert_aita\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "#Training model\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3a8266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix + classification report \n",
    "preds_output = trainer.predict(tokenized_val)\n",
    "y_pred_bert = np.argmax(preds_output.predictions, axis=-1)\n",
    "y_true = val_df[\"labels\"].to_numpy()\n",
    "\n",
    "print(classification_report(y_true, y_pred_bert, target_names=[\"YTA\", \"NTA\", \"ES\"]))\n",
    "\n",
    "cm_bert = confusion_matrix(y_true, y_pred_bert, labels=[0, 1, 2])\n",
    "disp = ConfusionMatrixDisplay(cm_bert, display_labels=[\"YTA\", \"NTA\", \"ES\"])\n",
    "disp.plot(values_format=\"d\")\n",
    "plt.title(\"DistilBERT Fine-tune (1 epoch)\")\n",
    "\n",
    "plt.savefig(OUT_PLOTS_BERT / \"bert_1epoch_cm.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "report_dict = classification_report(\n",
    "    y_true,\n",
    "    y_pred_bert,\n",
    "    target_names=[\"YTA\", \"NTA\", \"ES\"],\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "report_df.to_csv(OUT_REPORTS_BERT / \"bert_epoch1_classification_report.csv\")  \n",
    "report_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dae7db",
   "metadata": {},
   "source": [
    "### 6) DistilBERT fine-tuning (2 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training arguments + trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./training/distilbert_aita\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "#training model + evaulate\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff4121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting predictions and making report + cm\n",
    "preds_output = trainer.predict(tokenized_val)\n",
    "y_pred_bert = np.argmax(preds_output.predictions, axis=-1)\n",
    "y_true = val_df[\"labels\"].to_numpy()\n",
    "\n",
    "report_dict = classification_report(\n",
    "    y_true,\n",
    "    y_pred_bert,\n",
    "    target_names=[\"YTA\", \"NTA\", \"ES\"],\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "report_df.to_csv(OUT_REPORTS_BERT / \"bert_epoch2_classification_report.csv\") \n",
    "report_df\n",
    "\n",
    "cm_bert = confusion_matrix(y_true, y_pred_bert, labels=[0, 1, 2])\n",
    "disp = ConfusionMatrixDisplay(cm_bert, display_labels=[\"YTA\", \"NTA\", \"ES\"])\n",
    "disp.plot(values_format=\"d\")\n",
    "plt.title(\"DistilBERT Fine-tuned (2 epochs)\")\n",
    "\n",
    "plt.savefig(OUT_PLOTS_BERT / \"bert_2epochs_cm.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dbe7c2",
   "metadata": {},
   "source": [
    "### 7) DistilBERT (2 epochs) with class-weighted loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e600d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute class weights based on training label distribution\n",
    "classes = np.array([0, 1, 2])\n",
    "weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=train_df[\"labels\"].to_numpy()\n",
    ")\n",
    "class_weights = torch.tensor(weights, dtype=torch.float)\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb217c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom Trainer overriding loss computation to apply class-weighted cross-entropy\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=class_weights.to(logits.device))\n",
    "        loss = loss_fct(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abc1ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./training/distilbert_aita\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "#Training model + evaulate\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e5a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting preds and making report \n",
    "preds_output_w2 = trainer.predict(tokenized_val)\n",
    "y_pred_bert = np.argmax(preds_output_w2.predictions, axis=-1)\n",
    "y_true = val_df[\"labels\"].to_numpy()\n",
    "\n",
    "report_dict_w2 = classification_report(\n",
    "    y_true,\n",
    "    y_pred_bert,\n",
    "    target_names=[\"YTA\", \"NTA\", \"ES\"],\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "report_df_w2 = pd.DataFrame(report_dict_w2).transpose()\n",
    "report_df_w2.to_csv(OUT_REPORTS_BERT / \"bert_w_epoch2_classification_report.csv\")\n",
    "\n",
    "report_df_w2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfef9630",
   "metadata": {},
   "source": [
    "### 8) External Dataset Evaluation\n",
    "Tests generalization to a different AITA dataset with a different annotation scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a8a1314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "External dataset shape: (11670, 5)\n",
      "External dataset columns: ['pid', 'title', 'post', 'full post', 'verdict']\n",
      "\n",
      "Raw external verdict distribution:\n",
      " verdict\n",
      "user_ok          6000\n",
      "user_is_fault    5670\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Load in data\n",
    "path_ext = DATA_DIR / \"data_test.csv\"\n",
    "test_df = pd.read_csv(path_ext)\n",
    "print(\"External dataset shape:\", test_df.shape)\n",
    "print(\"External dataset columns:\", list(test_df.columns))\n",
    "print(\"\\nRaw external verdict distribution:\\n\", test_df[\"verdict\"].astype(str).value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a493c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mapped label distribution (including NaN):\n",
      " labels\n",
      "1    6000\n",
      "0    5670\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dropped 0 rows due to unmapped verdicts.\n",
      "Final external dataset shape: (11670, 8)\n",
      "Final external label distribution:\n",
      " labels\n",
      "0    5670\n",
      "1    6000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Combine title + post into text field + applying clean_text (same style as primary dataset)\n",
    "test_df[\"text\"] = test_df[\"title\"].fillna(\"\") + \" \" + test_df[\"post\"].fillna(\"\") \n",
    "test_df[\"text\"] = test_df[\"text\"].astype(str).apply(clean_text)\n",
    "\n",
    "#Normalize verdict labels\n",
    "test_df[\"verdict_norm\"] = test_df[\"verdict\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "#Map external labels: binary scheme\n",
    "label_map_ext = {\n",
    "    \"user_is_fault\": 0,  # YTA\n",
    "    \"user_ok\": 1         # NTA\n",
    "}\n",
    "\n",
    "test_df[\"labels\"] = test_df[\"verdict_norm\"].map(label_map_ext)\n",
    "\n",
    "print(\"\\nMapped label distribution (including NaN):\\n\", test_df[\"labels\"].value_counts(dropna=False))\n",
    "\n",
    "#Drop rows with unmapped verdicts\n",
    "before = len(test_df)\n",
    "test_df = test_df[test_df[\"labels\"].notna()].reset_index(drop=True)\n",
    "after = len(test_df)\n",
    "\n",
    "print(f\"\\nDropped {before - after} rows due to unmapped verdicts.\")\n",
    "print(\"Final external dataset shape:\", test_df.shape)\n",
    "print(\"Final external label distribution:\\n\", test_df[\"labels\"].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3c670b",
   "metadata": {},
   "source": [
    "#### 8.1) DistilBERT evaluation on external dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dc304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to Hugging Face Dataset\n",
    "test_hf = Dataset.from_pandas(test_df[[\"text\", \"labels\"]].reset_index(drop=True))\n",
    "\n",
    "def tokenize_ext(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_test = test_hf.map(tokenize_ext, batched=True)\n",
    "\n",
    "#Predict using the existing trainer/model (no training)\n",
    "preds = trainer.predict(tokenized_test)\n",
    "y_pred = np.argmax(preds.predictions, axis=1)\n",
    "y_true = test_df[\"labels\"].to_numpy()\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        labels=[0, 1],\n",
    "        target_names=[\"YTA\", \"NTA\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "#Save report\n",
    "bert_ext_report = classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    labels=[0, 1],\n",
    "    target_names=[\"YTA\", \"NTA\"],\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "bert_ext_df = pd.DataFrame(bert_ext_report).transpose()\n",
    "bert_ext_df.to_csv(\n",
    "    OUT_REPORTS / \"bert\" / \"bert_external_test_classification_report.csv\"\n",
    ")\n",
    "\n",
    "print(\"\\nSaved: classification_reports/bert/bert_external_test_classification_report.csv\")\n",
    "bert_ext_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f556418",
   "metadata": {},
   "source": [
    "#### 8.2) TF-IDF baseline evaluation on external dataset (binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573148ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform external texts using the *already fitted* TF-IDF vectorizer\n",
    "X_test_vec = tfidf_vectorizer.transform(test_df[\"text\"])\n",
    "y_test = test_df[\"labels\"].to_numpy()\n",
    "\n",
    "#Predict using the *already fitted* logistic regression classifier\n",
    "y_pred_tfidf_ext = clf.predict(X_test_vec)\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        y_pred_tfidf_ext,\n",
    "        labels=[0, 1],\n",
    "        target_names=[\"YTA\", \"NTA\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "#Save report to correct folder\n",
    "tfidf_ext_report = classification_report(\n",
    "    y_test,\n",
    "    y_pred_tfidf_ext,\n",
    "    labels=[0, 1],\n",
    "    target_names=[\"YTA\", \"NTA\"],\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "tfidf_ext_df = pd.DataFrame(tfidf_ext_report).transpose()\n",
    "tfidf_ext_df.to_csv(\n",
    "    OUT_REPORTS / \"tfidf\" / \"tfidf_external_test_classification_report.csv\"\n",
    ")\n",
    "\n",
    "print(\"\\nSaved: classification_reports/tfidf/tfidf_external_test_classification_report.csv\")\n",
    "tfidf_ext_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71275d81",
   "metadata": {},
   "source": [
    "### 9) Token-level Interpretability (Grad x Input)\n",
    "This section analyzes which tokens contribute most strongly to YTA vs. NTA predictions using gradient × input attribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2cc839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient x input attribution\n",
    "def token_importance_gradxinput(\n",
    "    text,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    target_class=None,\n",
    "    max_length=256\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute token-level importance using gradient × input.\n",
    "\n",
    "    If target_class is None:\n",
    "        explains the model's predicted class\n",
    "    If target_class is provided (0=YTA, 1=NTA):\n",
    "        forces explanation toward that class\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_attention_mask=True\n",
    "    )\n",
    "\n",
    "    input_ids = encoded[\"input_ids\"].to(device)\n",
    "    attention_mask = encoded[\"attention_mask\"].to(device)\n",
    "\n",
    "    embedding_layer = model.get_input_embeddings()\n",
    "    embeds = embedding_layer(input_ids)\n",
    "    embeds.requires_grad_(True)\n",
    "\n",
    "    outputs = model(inputs_embeds=embeds, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "\n",
    "    pred_class = torch.argmax(logits, dim=-1).item()\n",
    "    if target_class is None:\n",
    "        target_class = pred_class\n",
    "\n",
    "    model.zero_grad()\n",
    "    logits[0, target_class].backward()\n",
    "\n",
    "    grads = embeds.grad\n",
    "    token_scores = (grads * embeds).sum(dim=-1).squeeze(0)\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze(0))\n",
    "    scores = token_scores.detach().cpu().numpy()\n",
    "\n",
    "    rows = []\n",
    "    for tok, score in zip(tokens, scores):\n",
    "        if tok in [tokenizer.cls_token, tokenizer.sep_token, tokenizer.pad_token]:\n",
    "            continue\n",
    "        rows.append((tok, abs(score)))\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"token\", \"importance\"])\n",
    "    if df.empty:\n",
    "        return df, pred_class, target_class\n",
    "\n",
    "    df[\"importance_norm\"] = df[\"importance\"] / df[\"importance\"].max()\n",
    "\n",
    "    # Merge wordpieces (##)\n",
    "    merged_tokens = []\n",
    "    merged_scores = []\n",
    "\n",
    "    for tok, score in zip(df[\"token\"], df[\"importance_norm\"]):\n",
    "        if tok.startswith(\"##\") and merged_tokens:\n",
    "            merged_tokens[-1] += tok[2:]\n",
    "            merged_scores[-1] = max(merged_scores[-1], score)\n",
    "        else:\n",
    "            merged_tokens.append(tok)\n",
    "            merged_scores.append(score)\n",
    "\n",
    "    df_merged = pd.DataFrame({\n",
    "        \"token\": merged_tokens,\n",
    "        \"importance_norm\": merged_scores\n",
    "    }).sort_values(\"importance_norm\", ascending=False)\n",
    "\n",
    "    return df_merged.reset_index(drop=True), pred_class, target_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6307f50a",
   "metadata": {},
   "source": [
    "#### 9.1) Single-example attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3912cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0  # index of example to inspect\n",
    "text = test_df.loc[i, \"text\"]\n",
    "\n",
    "# Explain predicted class\n",
    "df_tok, pred_class, _ = token_importance_gradxinput(\n",
    "    text=text,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(\"Predicted class:\", pred_class)\n",
    "print(df_tok.head(30))\n",
    "\n",
    "# Force explanation toward YTA\n",
    "df_tok_yta, _, _ = token_importance_gradxinput(\n",
    "    text=text,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    target_class=0\n",
    ")\n",
    "\n",
    "print(df_tok_yta.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f2448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contrastice attribution: YTA vs. NTA (single post)\n",
    "df_yta, _, _ = token_importance_gradxinput(text, model, tokenizer, target_class=0)\n",
    "df_nta, _, _ = token_importance_gradxinput(text, model, tokenizer, target_class=1)\n",
    "\n",
    "df_compare = (\n",
    "    df_yta.merge(df_nta, on=\"token\", how=\"outer\", suffixes=(\"_yta\", \"_nta\"))\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "df_compare[\"diff\"] = (\n",
    "    df_compare[\"importance_norm_yta\"] - df_compare[\"importance_norm_nta\"]\n",
    ")\n",
    "\n",
    "df_compare = df_compare.sort_values(\n",
    "    \"diff\", key=lambda x: x.abs(), ascending=False\n",
    ")\n",
    "\n",
    "# Save tables\n",
    "df_compare.to_csv(\n",
    "    OUT_TOKENS / \"bert_token_importance_yta_vs_nta.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "df_compare.head(50).to_csv(\n",
    "    OUT_TOKENS / \"bert_token_importance_yta_vs_nta_top50.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(df_compare.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4efce9b",
   "metadata": {},
   "source": [
    "#### 9.2) Aggregated contrastive attribution across multiple posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af769db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_contrastive_tokens(\n",
    "    df_source,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    n_samples=50,\n",
    "    max_length=256\n",
    "):\n",
    "    rng = np.random.default_rng(SEED)\n",
    "    indices = rng.choice(\n",
    "        df_source.index.to_numpy(),\n",
    "        size=min(n_samples, len(df_source)),\n",
    "        replace=False\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for idx in indices:\n",
    "        text = df_source.loc[idx, \"text\"]\n",
    "\n",
    "        df_yta, _, _ = token_importance_gradxinput(\n",
    "            text, model, tokenizer, target_class=0, max_length=max_length\n",
    "        )\n",
    "        df_nta, _, _ = token_importance_gradxinput(\n",
    "            text, model, tokenizer, target_class=1, max_length=max_length\n",
    "        )\n",
    "\n",
    "        df_merge = (\n",
    "            df_yta.merge(df_nta, on=\"token\", how=\"outer\", suffixes=(\"_yta\", \"_nta\"))\n",
    "            .fillna(0)\n",
    "        )\n",
    "\n",
    "        df_merge[\"diff\"] = (\n",
    "            df_merge[\"importance_norm_yta\"] - df_merge[\"importance_norm_nta\"]\n",
    "        )\n",
    "        rows.append(df_merge)\n",
    "\n",
    "    df_all = pd.concat(rows)\n",
    "    df_agg = (\n",
    "        df_all.groupby(\"token\")[[\"importance_norm_yta\", \"importance_norm_nta\", \"diff\"]]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    df_agg[\"abs_diff\"] = df_agg[\"diff\"].abs()\n",
    "    return df_agg.sort_values(\"abs_diff\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2034da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare_agg = aggregate_contrastive_tokens(\n",
    "    test_df,\n",
    "    model,\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "df_compare_agg.to_csv(\n",
    "    OUT_TOKENS / \"bert_token_contrastive_aggregated.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# Plot aggregated contrastive tokens\n",
    "top_n = 25\n",
    "plot_df = df_compare_agg.head(top_n).sort_values(\"diff\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(plot_df[\"token\"], plot_df[\"diff\"])\n",
    "plt.axvline(0, linewidth=1)\n",
    "plt.title(\"Aggregated token attribution: YTA vs NTA\")\n",
    "plt.xlabel(\"Mean importance difference (YTA − NTA)\")\n",
    "plt.ylabel(\"Token\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    OUT_TOKENS / \"bert_token_contrastive_top_tokens.png\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
